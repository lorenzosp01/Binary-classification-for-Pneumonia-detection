{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Dependencies and Setup 📥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms as tt\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.nn.functional as F\n",
    "from cnn import Net\n",
    "from utils import save_model, load_model, display_metrics, plot_graphs\n",
    "from collections import Counter\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_curve, \n",
    "    roc_auc_score\n",
    ")\n",
    "from datasetLoader.MergedDataset import MergedDataset, to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameter *loadExistingModel* to 'True' if you want to load an existing model and specify wich model do you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (e.g., resizing, normalization)\n",
    "transform = tt.Compose([tt.Resize(255),\n",
    "                        tt.CenterCrop(224),\n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(mean=0.482, std=0.236, inplace=True)\n",
    "                        ])\n",
    "\n",
    "# Define train and validation split value\n",
    "train_perc = 0.8\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Define learning rate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Seed\n",
    "seed = 2024\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Model settings\n",
    "loadExistingModel = True\n",
    "modelName = \"./models/modelChestXray.pth\"\n",
    "saveModel = not loadExistingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Data 📚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MergedDataset(device, \n",
    "                                    transformLoadingChest=transform, \n",
    "                                    chest_xray=True, cheX=False, kaggle_rsna=False)\n",
    "train_dl, test_dl = dataset.getDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Merged dataset lenght: {dataset.getSize()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_count = dataset.getTrainClasses()\n",
    "test_class_count = dataset.getTestClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "values = [train_class_count[0], train_class_count[1], test_class_count[0], test_class_count[1]]\n",
    "\n",
    "# Data for the categories\n",
    "categories = ['Normal', 'Pneumonia']\n",
    "\n",
    "for i in range(2):\n",
    "    # Create the bar chart\n",
    "    ax[i].bar(categories, [values[0 + i*2], values[1 + i*2]], color=['green', 'red'])\n",
    "    # Add titles and labels\n",
    "    ax[i].set_title('Train Categories' if i == 0 else 'Test Categories')\n",
    "    ax[i].set_ylabel('Count')\n",
    "    ax[i].set_xlabel('Category')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(f'Train classes:\\n\\tNormal:\\t\\t{train_class_count[0]}\\n\\tPneumonia:\\t{train_class_count[1]}')\n",
    "print(f'Test classes:\\n\\tNormal:\\t\\t{test_class_count[0]}\\n\\tPneumonia:\\t{test_class_count[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))\n",
    "images, labels = batch\n",
    "print(f'Image shape: {images[0].shape}\\nLabel shape: {labels[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.cpu().permute(1, 2, 0))\n",
    "    ax[idx].title.set_text(batch[1][idx].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Building 🏗️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = False\n",
    "net = None\n",
    "\n",
    "if loadExistingModel:\n",
    "    net = load_model(modelName)\n",
    "\n",
    "if net == None:\n",
    "    print('The model does not exist!\\nCreating and training model...')\n",
    "    net = to_device(Net(), device)\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Define weights for the cross entropy loss\n",
    "    weight = torch.FloatTensor([train_class_count[1]/(train_class_count[0]+train_class_count[1]), train_class_count[0]/(train_class_count[0]+train_class_count[1])]).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    loss_values = []\n",
    "    net.train()\n",
    "    trained = True\n",
    "    for epoch in range(50):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dl, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = to_device(inputs, device), to_device(labels, device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = F.cross_entropy(outputs, labels, weight=weight)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        loss_values.append(running_loss / len(train_dl))\n",
    "        print(f'Epoch: {epoch}, loss: {(running_loss / len(train_dl))}')\n",
    "else:\n",
    "    print('The model exist and exists and has been loaded')\n",
    "    trained = False\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    print('Model info:')\n",
    "    for param_tensor in net.state_dict():\n",
    "        print(\"\\t\", param_tensor, \"\\t\", net.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if saveModel:\n",
    "    save_model(modelName, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Plot Loss 📈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(loss_values, marker='o', label='Loss')\n",
    "    plt.title('Loss Values Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testing Model 🧪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Test on chest_xray-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_test = []\n",
    "prob = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        images, labels = data\n",
    "        images, labels = to_device(images, device), to_device(labels, device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "        prob.extend(torch.nn.functional.softmax(outputs.cpu(), dim=1)[:, 1])\n",
    "    fprChest, tprChest, thresholds = roc_curve(y_test, prob)\n",
    "    roc_aucChest = roc_auc_score(y_test, prob)\n",
    "\n",
    "    distances = np.sqrt(fprChest**2 + (1 - tprChest)**2)\n",
    "    best_threshold = thresholds[np.argmin(distances)]\n",
    "    new_preds = [1 if score > best_threshold else 0 for score in prob]\n",
    "\n",
    "    cm = confusion_matrix(y_test, new_preds)\n",
    "    dispChest = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    accuracyChest = accuracy_score(y_test, new_preds)\n",
    "    precisionChest = precision_score(y_test, new_preds)\n",
    "    recallChest = recall_score(y_test, new_preds)\n",
    "    f1Chest = f1_score(y_test, new_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Test on cheX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2.0 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tt.Compose([tt.Resize(255),\n",
    "                        tt.CenterCrop(224),\n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(mean=0.5017, std=0.2905, inplace=True)\n",
    "                        ])\n",
    "\n",
    "dataset = MergedDataset(device, \n",
    "                                    transformLoadingCheX=transform,\n",
    "                                    chest_xray=False, cheX=True, kaggle_rsna=False, \n",
    "                                    train_percentage=0, \n",
    "                                    split_seed=2024)\n",
    "_, test_dl = dataset.getDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.2.1 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_test = []\n",
    "prob = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        images, labels = data\n",
    "        images, labels = to_device(images, device), to_device(labels, device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "        prob.extend(torch.nn.functional.softmax(outputs.cpu(), dim=1)[:, 1])\n",
    "    fprCheX, tprCheX, thresholds = roc_curve(y_test, prob)\n",
    "    roc_aucCheX = roc_auc_score(y_test, prob)\n",
    "\n",
    "    distances = np.sqrt(fprCheX**2 + (1 - tprCheX)**2)\n",
    "    best_threshold = thresholds[np.argmin(distances)]\n",
    "    new_preds = [1 if score > best_threshold else 0 for score in prob]\n",
    "\n",
    "    cm = confusion_matrix(y_test, new_preds)\n",
    "    dispCheX = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    accuracyCheX = accuracy_score(y_test, new_preds)\n",
    "    precisionCheX = precision_score(y_test, new_preds)\n",
    "    recallCheX = recall_score(y_test, new_preds)\n",
    "    f1CheX = f1_score(y_test, new_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Test on kaggle-rsna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.0 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tt.Compose([tt.Resize(255),\n",
    "                        tt.CenterCrop(224),\n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(mean=0.4841, std=0.2428, inplace=True)\n",
    "                        ])\n",
    "\n",
    "dataset = MergedDataset(device, \n",
    "                                    transformLoadingRsna=transform, \n",
    "                                    chest_xray=False, cheX=False, kaggle_rsna=True, \n",
    "                                    train_percentage=0, \n",
    "                                    kaggleRsna_drop_normal_percentage=0.50,\n",
    "                                    split_seed=2024)\n",
    "_, test_dl = dataset.getDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.3.1 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "y_test = []\n",
    "prob = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dl:\n",
    "        images, labels = data\n",
    "        images, labels = to_device(images, device), to_device(labels, device)\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_test.extend(labels.cpu().numpy())\n",
    "        prob.extend(torch.nn.functional.softmax(outputs.cpu(), dim=1)[:, 1])\n",
    "    fprRsna, tprRsna, thresholds = roc_curve(y_test, prob)\n",
    "    roc_aucRsna = roc_auc_score(y_test, prob)\n",
    "\n",
    "    distances = np.sqrt(fprRsna**2 + (1 - tprRsna)**2)\n",
    "    best_threshold = thresholds[np.argmin(distances)]\n",
    "    new_preds = [1 if score > best_threshold else 0 for score in prob]\n",
    "\n",
    "    cm = confusion_matrix(y_test, new_preds)\n",
    "    dispRsna = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    accuracyRsna = accuracy_score(y_test, new_preds)\n",
    "    precisionRsna = precision_score(y_test, new_preds)\n",
    "    recallRsna = recall_score(y_test, new_preds)\n",
    "    f1Rsna = f1_score(y_test, new_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Test Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.4.1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_metrics('CXr', 'CXr', [roc_aucChest, accuracyChest, precisionChest, recallChest, f1Chest])\n",
    "display_metrics('CXr', 'CheX', [roc_aucCheX, accuracyCheX, precisionCheX, recallCheX, f1CheX])\n",
    "display_metrics('CXr', 'RSNA', [roc_aucRsna, accuracyRsna, precisionRsna, recallRsna, f1Rsna])\n",
    "\n",
    "print([roc_aucChest, accuracyChest, precisionChest, recallChest, f1Chest, roc_aucCheX, accuracyCheX, precisionCheX, recallCheX, f1CheX, roc_aucRsna, accuracyRsna, precisionRsna, recallRsna, f1Rsna])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7.4.2 Grphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs('CXr', roc_aucChest, fprChest, tprChest, dispChest, [accuracyChest, precisionChest, recallChest, f1Chest])\n",
    "plot_graphs('CheX', roc_aucCheX, fprCheX, tprCheX, dispCheX, [accuracyCheX, precisionCheX, recallCheX, f1CheX])\n",
    "plot_graphs('RSNA', roc_aucRsna, fprRsna, tprRsna, dispRsna, [accuracyRsna, precisionRsna, recallRsna, f1Rsna])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
