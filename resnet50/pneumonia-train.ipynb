{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import random\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import dataloaders.nih_xray8 as nih_xray8\n",
    "import dataloaders.chexpert as chexpert\n",
    "import dataloaders.kaggle_rsna as kaggle_rsna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cwd if required\n",
    "# os.chdir('/projects/resnet50')\n",
    "\n",
    "train = True\n",
    "resume_training = False\n",
    "# model will be saved to this file if train is True,\n",
    "# otherwise this file will be loaded as the model to test\n",
    "model_file = \"resnet_chex.pth\"\n",
    "resnet_model = PneumoniaResnet()\n",
    "\n",
    "# Dataset paths\n",
    "DATASET1_PATH = '/bigdata/chest_xray-3'\n",
    "DATASET2_PATH = '/bigdata/CheXpert-v1.0-small'\n",
    "DATASET3_PATH = '/bigdata/kaggle-rsna'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data will be loaded, splitted in train / test and the following transformations will be applied:\n",
    "\n",
    "1. Resize and crop to 224x224 as many images are of different sizes\n",
    "2. Data Augmentation\n",
    "3. Convert images into PyTorch tensors\n",
    "4. Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_dir = DATASET1_PATH\n",
    "dataset1 = ImageFolder(data1_dir, \n",
    "                      # common transforms for all the splits\n",
    "                      transform=tt.Compose([tt.Resize((224, 224)),\n",
    "                                            tt.ToTensor(),\n",
    "                                            tt.Normalize(mean=0.482, std=0.236, inplace=True) # dataset1 mean and std\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_dir = DATASET2_PATH\n",
    "\n",
    "transform2=tt.Compose([ tt.Resize((224, 224)),\n",
    "                        # common transforms for all the splits\n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(mean=0.5017, std=0.2905, inplace=True) # dataset2 mean and std\n",
    "                        ])\n",
    "\n",
    "dataset2 = chexpert.CheXDataset(data2_dir, [transform2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_dir = DATASET3_PATH\n",
    "\n",
    "transform3=tt.Compose([ # common transforms for all the splits\n",
    "                        tt.ToTensor(),\n",
    "                        tt.Normalize(mean=0.4841, std=0.2428, inplace=True) # dataset3 mean and std\n",
    "                        ])\n",
    "\n",
    "dataset3 = kaggle_rsna.RSNADataset(data3_dir, [transform3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset1), len(dataset2), len(dataset3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the dataset to use in train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = torch.utils.data.ConcatDataset([dataset1])\n",
    "#dataset = torch.utils.data.ConcatDataset([dataset2])\n",
    "dataset = torch.utils.data.ConcatDataset([dataset3])\n",
    "\n",
    "# we used ConcatDataset to allow experimenting with multiple datasets\n",
    "# howver, we did not merge datasets at the end. So only one was used per each run in our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset in Train, Validation & Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed so we get the same sampling every time for reproducibility\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this class is used as a wrapper for the dataset to apply transforms\n",
    "# this allows to apply data augmentation only to the training set\n",
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_size = round(len(dataset)*0.8) # 80% for training and validation\n",
    "test_size = len(dataset) - train_val_size # 20% for testing\n",
    "\n",
    "train_size = round(train_val_size * 0.8)  # 80% of train_val_size for training\n",
    "val_size = train_val_size - train_size    # The rest for validation\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_transform = tt.Compose([  # data augmentation is only applied to the training set\n",
    "                                tt.RandomRotation(10),\n",
    "                                tt.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                            ])\n",
    "\n",
    "val_transform = tt.Compose([ # no further transformations required\n",
    "                            ])\n",
    "\n",
    "# apply the transforms to the datasets\n",
    "train_ds = TransformedDataset(train_ds, train_transform)\n",
    "val_ds = TransformedDataset(val_ds, val_transform)\n",
    "test_ds = TransformedDataset(test_ds, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the class distribution\n",
    "\n",
    "This will be used to assign the weights to the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = {}\n",
    "indices = train_ds.subset.indices\n",
    "\n",
    "for global_idx in indices:\n",
    "    # Trova il sotto-dataset corretto e l'indice locale\n",
    "    for j, offset in enumerate(dataset.cumulative_sizes):\n",
    "        if global_idx < offset:\n",
    "            local_idx = global_idx if j == 0 else global_idx - dataset.cumulative_sizes[j - 1]\n",
    "            subset = dataset.datasets[j]\n",
    "            break\n",
    "\n",
    "    label = subset.targets[local_idx]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "\n",
    "# print the class distribution\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the data loaders and the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print if GPU is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if GPU is available, set the device to GPU\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to move the tensors to the chosen device\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeviceDataLoader wraps the data loader in a way to return data already moved to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the wrapped dataloaders and move the model to the chosen device\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "val_dl = DeviceDataLoader(val_dl, device)\n",
    "\n",
    "model = to_device(resnet_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters used during training\n",
    "\n",
    "epochs = 80\n",
    "lr = 0.0001\n",
    "grad_clip = None\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam\n",
    "# weighted loss for data class imbalance\n",
    "class_0_weight = class_count[1]/len(train_ds)\n",
    "class_1_weight = class_count[0]/len(train_ds)\n",
    "weight = torch.FloatTensor([class_0_weight, class_1_weight]).to(device)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for loading the model from a previously saved one\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    #model = PneumoniaResnetB()\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    #for parameter in model.parameters():\n",
    "    #    parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "if train and resume_training:\n",
    "    model = load_checkpoint(model_file).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    history, optimizer, best_loss = fit(epochs, lr, model, train_dl, val_dl, weight, \n",
    "                                        grad_clip=grad_clip,\n",
    "                                        weight_decay=weight_decay,\n",
    "                                        opt_func=opt_func, use_best_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    print('Best loss is:', best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "if train:\n",
    "    bestmodel = {'model': resnet_model,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'optimizer' : optimizer.state_dict()}\n",
    "    \n",
    "    torch.save(bestmodel, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for loading the model from a previously saved one\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "if not train:\n",
    "    model = load_checkpoint(model_file).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Accuracy_loss_plots'></a>\n",
    "# 6. Accuracy and Loss Plots\n",
    "\n",
    "We made plots of the accuracy and loss for the training and validation data. This gives us an idea of how our model is performing (e.g., underfitting, overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Accuracy and Loss \n",
    "if train:\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    t = f.suptitle('Performance', fontsize=12)\n",
    "    f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "    \n",
    "    epoch_list = list(range(1,epochs+1))\n",
    "    ax1.plot(epoch_list, history['train_acc'], label='Train Accuracy')\n",
    "    ax1.plot(epoch_list, history['val_acc'], label='Validation Accuracy')\n",
    "    ax1.set_xticks(np.arange(0, epochs+1, 5))\n",
    "    ax1.set_ylabel('Accuracy Value')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_title('Accuracy')\n",
    "    l1 = ax1.legend(loc=\"best\")\n",
    "    \n",
    "    ax2.plot(epoch_list, history['train_loss'], label='Train Loss')\n",
    "    ax2.plot(epoch_list, history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_xticks(np.arange(0, epochs+1, 5))\n",
    "    ax2.set_ylabel('Loss Value')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_title('Loss')\n",
    "    l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_predict(model, test_loader):\n",
    "    model.eval()\n",
    "    # perform testing for each batch\n",
    "    outputs = [model.validation_step(batch) for batch in test_loader] \n",
    "    results = model.test_prediction(outputs)                          \n",
    "    print('test_loss: {:.4f}, test_acc: {:.4f}'\n",
    "          .format(results['test_loss'], results['test_acc']))\n",
    "    \n",
    "    return results['test_preds'], results['test_labels'], results['test_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate test data loader\n",
    "test_dl = DataLoader(test_dataset, batch_size=256, num_workers=4, pin_memory=True)\n",
    "test_dl = DeviceDataLoader(test_dl, device)\n",
    "\n",
    "# Evaluate test set\n",
    "preds,labels,outs = test_predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold is chosen as the point on the ROC curve that minimizes the Euclidean distance to the top-left corner (optimal point), representing the best trade-off between false positive rate and true positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = F.softmax(torch.tensor(outs), dim=1)[:, 1]\n",
    "scores = scores.detach().numpy()\n",
    "    \n",
    "fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "\n",
    "distances = np.sqrt(fpr**2 + (1 - tpr)**2)\n",
    "best_threshold = thresholds[np.argmin(distances)]\n",
    "preds = [1 if score > best_threshold else 0 for score in scores]\n",
    "\n",
    "# Plot the curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve')# (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=1)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC Curve', fontsize=14)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Chosen threshold:\", best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC_AUC score\n",
    "roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Evaluation_metrics'></a>\n",
    "# 8. Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm  = confusion_matrix(labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.xlabel('Predicted Label',fontsize=18)\n",
    "plt.ylabel('True Label',fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Performance Metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (np.array(preds) == np.array(labels)).sum() / len(preds)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"Accuracy of the model is {:.3f}\".format(accuracy))\n",
    "print(\"Recall of the model is {:.3f}\".format(recall))\n",
    "print(\"Precision of the model is {:.3f}\".format(precision))\n",
    "print(\"F1 Score of the model is {:.3f}\".format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "021abf31001346bbb2fdc6610b246771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "558a03d0386645098828574b043720e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a027a7a736c0457ab3714f829ef31330",
       "max": 102502400,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bd11909f24f64cb0a453155d795c024c",
       "value": 102502400
      }
     },
     "747bb6bf3d2f49fab5b169fb17e483d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_558a03d0386645098828574b043720e1",
        "IPY_MODEL_c9b1976bbc054230b99910f49f3d4ff2"
       ],
       "layout": "IPY_MODEL_99eaac7da83445f789284dc82f89e8aa"
      }
     },
     "99eaac7da83445f789284dc82f89e8aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a00c8f12fe414867b91297333027389c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a027a7a736c0457ab3714f829ef31330": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd11909f24f64cb0a453155d795c024c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c9b1976bbc054230b99910f49f3d4ff2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a00c8f12fe414867b91297333027389c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_021abf31001346bbb2fdc6610b246771",
       "value": " 97.8M/97.8M [00:15&lt;00:00, 6.73MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
